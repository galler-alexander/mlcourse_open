{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 3\n",
    "Автор материала: Павел Нестеров (@mephistopheies). Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашняя работа №4\n",
    "## <center> Логистическая регрессия в задаче тегирования вопросов StackOverflow\n",
    "\n",
    "**Надо вывести формулы, где это просится (да, ручка и бумажка), заполнить код в клетках и выбрать ответы в [веб-форме](https://docs.google.com/forms/d/100c3Ek94UL-VRwXrN4lxCSnGjfJrl6Gc96G21DNCh4w).**\n",
    "\n",
    "## 0. Описание задачи\n",
    "\n",
    "В этой домашней работе мы с вами изучим и запрограммируем модель для прогнозирования тегов по тексту вопроса на базе многоклассовой логистической регрессии. В отличие от обычной постановки задачи классификации (multiclass), в данном случае один пример может принадлежать одновременно к нескольким классам (multilabel). Мы будем реализовывать онлайн-версию алгоритма multilabel-классификации.\n",
    "\n",
    "Мы будем использовать небольшую выборку из протеггированных вопросов с сайта StackOverflow размером в 125 тысяч примеров (около 150 Мб, скачайте по [этой](https://drive.google.com/open?id=0B4bl7YMqDnViYVo0V2FubFVhMFE) ссылке).\n",
    "\n",
    "PS: Можно показать, что такая реализация совсем не эффективная и проще было бы использовать векторизированные вычисления. Для данного датасета так и есть. Но на самом деле подобные реализации используются в жизни, но естественно, написаны они не на Python. Например, в онлайн-моделях прогнозирования [CTR](https://en.wikipedia.org/wiki/Click-through_rate) юзеру показывается баннер, затем в зависимости от наличия клика происходит обновление параметров модели. В реальной жизни параметров модели может быть несколько сотен миллионов, а у юзера из этих ста миллионов от силы сто или тысяча параметров отличны от нуля, векторизировать такие вычисления не очень эффективно. Обычно все это хранится в огромных кластерах в in-memory базах данных, а обработка пользователей происходит распределенно.\n",
    "\n",
    "PS2:\n",
    "- в процессе решения домашней работы вам придется работать с текстом, и у вас может возникнуть желание сделать очевидный препроцессинг, например привести все слова в нижний регистр, в-общем **этого делать не нужно, если не оговорено заранее в задании**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем версии используемых библиотек. Совпадут ли ответы в случае других версий - не гарантируется."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "CPython 3.6.1\n",
    "IPython 5.3.0\n",
    "\n",
    "numpy 1.14.0\n",
    "scipy 1.0.0\n",
    "pandas 0.22.0\n",
    "matplotlib 2.1.2\n",
    "sklearn 0.19.1\n",
    "\n",
    "compiler   : GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)\n",
    "system     : Darwin\n",
    "release    : 17.4.0\n",
    "machine    : x86_64\n",
    "processor  : i386\n",
    "CPU cores  : 8\n",
    "interpreter: 64bit\n",
    "Git hash   : 45c8c34462bbf54d2a05de99fb9f0a6491fa1e27\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.5.2\n",
      "IPython 6.2.1\n",
      "\n",
      "numpy 1.14.0\n",
      "scipy 1.0.0\n",
      "pandas 0.22.0\n",
      "matplotlib 2.1.2\n",
      "sklearn 0.19.1\n",
      "\n",
      "compiler   : GCC 5.4.0 20160609\n",
      "system     : Linux\n",
      "release    : 4.9.60-linuxkit-aufs\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "Git hash   : e7cad69ccd3812a87e62f51cf53b7133583b44da\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# поменяйте на свой путь\n",
    "DS_FILE_NAME = '../../data/stackoverflow_sample_125k.tsv'\n",
    "TAGS_FILE_NAME = '../../data/top10_tags.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'android', 'html', 'python', 'c#', 'php', 'jquery', 'c++', 'java', 'javascript', 'ios'}\n"
     ]
    }
   ],
   "source": [
    "top_tags = []\n",
    "with open(TAGS_FILE_NAME, 'r') as f:\n",
    "    for line in f:\n",
    "        top_tags.append(line.strip())\n",
    "top_tags = set(top_tags)\n",
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Многоклассовая логистическая регрессия\n",
    "\n",
    "Вспомним, как получается логистическая регрессия для двух классов $\\left\\{0, 1\\right\\}$, вероятность принадлежности объекта к классу $1$ выписывается по теореме Байеса:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = 1 \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} \\\\\n",
    "&=& \\dfrac{1}{1 + e^{-a}} \\\\\n",
    "&=& \\sigma\\left(a\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\vec{x}$ – вектор признаков объекта\n",
    "- $\\sigma$ – обозначение функции логистического сигмоида при скалярном аргументе\n",
    "- $a = \\log \\frac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} = \\sum_{i=0}^M w_i x_i$ – это отношение мы моделируем линейной функцией от признаков объекта и параметров модели\n",
    "\n",
    "Данное выражение легко обобщить до множества из $K$ классов, изменится только знаменатель в формуле Байеса. Запишем вероятность принадлежности объекта к классу $k$:\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = k \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right)}{\\sum_{i=1}^K p\\left(\\vec{x} \\mid c = i\\right)p\\left(c = i\\right)} \\\\\n",
    "&=& \\dfrac{e^{z_k}}{\\sum_{i=1}^{K}e^{z_i}} \\\\\n",
    "&=& \\sigma_k\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\sigma_k$ – обозначение функции softmax при векторном аргументе\n",
    "- $z_k = \\log p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right) = \\sum_{i=0}^M w_{ki} x_i$ – это выражение моделируется линейной функцией от признаков объекта и параметров модели для класса $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделирования полного правдоподобия примера мы используем [категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution), а лучше его логарифм (для удобства):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\mathcal{L} = \\log p\\left({\\vec{x}}\\right) &=& \\log \\prod_{i=1}^K \\sigma_i\\left(\\vec{z}\\right)^{y_i} \\\\\n",
    "&=& \\sum_{i=1}^K y_i \\log \\sigma_i\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "Получается хорошо знакомая нам функция [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) (если домножить на $-1$). Правдоподобие нужно максимизировать, а, соответственно, перекрестную энтропию нужно минимизировать. Продифференцировав по параметрам модели, мы _легко_ получим правила обновления весов для градиентного спуска, **проделайте этот вывод, если вы его не делали** (если вы вдруг сдались, то на [этом](https://www.youtube.com/watch?v=-WiR16raQf4) видео есть разбор вывода, понимание этого вам понадобится для дальнейшего выполнения задания; если предпочитаете текст, то и он есть [тут](https://www.ics.uci.edu/~pjsadows/notes.pdf) и [тут](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& x_m \\left(y_k - \\sigma_k\\left(\\vec{z}\\right)\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "В стандартной формулировке получается, что вектор $\\left(\\sigma_1, \\sigma_2, \\ldots, \\sigma_K\\right)$ образует дискретное вероятностное распределение, т.е. $\\sum_{i=1}^K \\sigma_i = 1$. Но в нашей постановке задачи каждый пример может иметь несколько тегов или одновременно принадлежать к нескольким классам. Для этого мы немного изменим модель:\n",
    "- будем считать, что все теги независимы друг от друга, т.е. каждый исход – это логистическая регрессия на два класса (либо есть тег, либо его нет), тогда вероятность наличия тега у примера запишется следующим образом (каждый тег/класс как и в многоклассовой логрегрессии имеет свой набор параметров):\n",
    "$$\\large p\\left(\\text{tag}_k \\mid \\vec{x}\\right) = \\sigma\\left(z_k\\right) = \\sigma\\left(\\sum_{i=1}^M w_{ki} x^i \\right)$$\n",
    "- наличие каждого тега мы будем моделировать с помощью <a href=\"https://en.wikipedia.org/wiki/Bernoulli_distribution\">распределения Бернулли</a>\n",
    "\n",
    "<font color=\"red\">Вопрос 1.</font> Ваше первое задание –  записать упрощенное выражение логарифма правдоподобия примера с признаками $\\vec{x}$. Как правило, многие алгоритмы оптимизации имеют интерфейс для минимизации функции, мы последуем этой же традиции и домножим полученное выражение на $-1$, а во второй части выведем формулы для минимизации полученного выражения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{L} = \\log p\\left({\\vec{x}}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "-\\mathcal{L} = -\\log p\\left({\\vec{x}}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "- \\mathcal{L} = -\\log \\prod_{i=1}^K \\sigma\\left(z_i\\right)^{y_i} \\left(1 - \\sigma\\left(z_i\\right)\\right)^{1 - y_i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "-\\mathcal{L} = -\\sum_{i=1}^K \\log \\sigma\\left(z_i\\right)^{y_i} \\left(1 - \\sigma\\left(z_i\\right)\\right)^{1 - y_i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "-\\mathcal{L} = -\\sum_{i=1}^K \\log \\sigma\\left(z_i\\right)^{y_i} + \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)^{1 - y_i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "-\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\begin{array}{rcl}\n",
    "    -\\mathcal{L} = -\\log p\\left(\\vec{x}\\right) &=& -\\log \\prod_{i=1}^K \\sigma\\left(z_i\\right)^{y_i} \\left(1 - \\sigma\\left(z_i\\right)\\right)^{1 - y_i} \\\\\n",
    "    &=& -\\sum_{i=1}^K \\log \\sigma\\left(z_i\\right)^{y_i} \\left(1 - \\sigma\\left(z_i\\right)\\right)^{1 - y_i} \\\\\n",
    "    &=& -\\sum_{i=1}^K \\log \\sigma\\left(z_i\\right)^{y_i} + \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)^{1 - y_i} \\\\\n",
    "    &=& -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. $\\large -\\mathcal{L} = -\\sum_{i=1}^M y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "2. $\\huge  -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "3. $\\large -\\mathcal{L} = -\\sum_{i=1}^K z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "4. $\\large -\\mathcal{L} = -\\sum_{i=1}^M z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вывод формулы обновления весов\n",
    "\n",
    "<font color=\"red\">Вопрос 2.</font> В качестве второго задания вам предоставляется возможность вывести формулу градиента для $-\\mathcal{L}$. Какой вид она будет иметь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{array}{rcl}\n",
    "-\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& -\\frac{\\partial}{\\partial w_{km}} \\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "-\\frac{\\partial \\mathcal{L}}{\\partial w_{km}}  = -\\left(y_k \\frac{1}{\\sigma\\left(z_k\\right)} \\sigma\\left(z_k\\right) \\left(1 - \\sigma\\left(z_k\\right)\\right) x_m - \\left(1 - y_i\\right) \\frac{1}{1 - \\sigma\\left(z_k\\right)} \\sigma\\left(z_k\\right) \\left(1 - \\sigma\\left(z_k\\right)\\right)x_m\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{array}{rcl}\n",
    "-\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& -\\frac{\\partial}{\\partial w_{km}} \\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "-\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -y_k \\left(\\left(1 - \\sigma\\left(z_k\\right)\\right) x_m - \\left(1 - y_i\\right) \\sigma\\left(z_k\\right) x_m\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "-\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(\\sigma\\left(z_k\\right) - y_k\\right)$\n",
    "2. $\\huge -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$\n",
    "3. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(\\sigma\\left(z_k\\right)x_m - y_k\\right)$\n",
    "4. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(y_k - \\sigma\\left(z_k\\right)x_m\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация базовой модели\n",
    "\n",
    "Вам предлагается каркас класса модели, разберите его внимательно, обращайте внимание на комментарии. Затем заполните пропуски, запустите полученную модель и ответьте на проверочный вопрос.\n",
    "\n",
    "Как вы могли уже заметить, при обновлении веса $w_{km}$ используется значение признака $x_m$, который равен $0$, если слова с индексом $m$ нет в предложении, и больше нуля, если такое слово есть. В нашем случае, чтобы не пересчитывать [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) самим или с помощью [sklearn.feature_extraction.text.CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), мы будем идти по словам предложения в порядке их следования. Если какое-то слово встречается несколько раз, то мы добавляем его в аккумулятор со своим весом. В итоге получится то же самое, как если сначала посчитать количество одинаковых слов и домножить на соответствующий вес. Соответственно, при вычислении линейной комбинации $z$ весов модели и признаков примера необходимо учитывать только ненулевые признаки объекта.\n",
    "\n",
    "Подсказка:\n",
    "- если реализовывать вычисление сигмоида так же, как в формуле, то при большом отрицательном значении $z$ вычисление $e^{-z}$ превратится в очень большое число, которое вылетит за допустимые пределы\n",
    "- в то же время $e^{-z}$ от большого положительного $z$ будет нулем\n",
    "- воспользуйтесь свойствами функции $\\sigma$ для того, чтобы пофиксить эту ошибку и реализовать $\\sigma$ без риска overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import json\n",
    "    import bz2\n",
    "    \n",
    "    with bz2.BZ2File('./file.jsonlines.bz2') as m_file:\n",
    "        for line in m_file:\n",
    "            result = json.loads(line)\n",
    "    \n",
    "            # Обработка\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы создаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        # z += ...\n",
    "                        # прибавляем вес для слова word тега tag\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sigma = ...\n",
    "                    if z >= 0:\n",
    "                        sigma = 1 / (1 + np.exp(-z))\n",
    "                    else:\n",
    "                        sigma = 1 - 1/(1 + np.exp(z))\n",
    "    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sample_loss += ...\n",
    "                    if y ==1:\n",
    "                        sample_loss += (-y * np.log(np.max([tolerance, sigma]))) \n",
    "                    else:\n",
    "                        sample_loss += (-(1 - y) * np.log(1 - np.min([1 - tolerance, sigma])))\n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        # dLdw = ...\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate * dLdw\n",
    "                        self._b[tag] -= -learning_rate * dLdw\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450c8d150a3144fe808773d78a7c562c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим эксемпляр модели и пройдемся по датасету\n",
    "model = LogRegressor()\n",
    "model.iterate_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, действительно ли значение отрицательного логарифмического правдоподобия уменьшалось. Так как мы используем стохастический градентный спуск, не стоит ожидать плавного падения функции ошибки. Мы воспользуемся скользящим средним с окном в 10 тысяч примеров, чтобы хоть как-то сгладить график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f058c077f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the loss function on the last 10k train samples: 19.74\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the loss function on the last 10k train samples: %0.2f' % np.mean(model._loss[-35000:-25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 3.</font>\n",
    "Вычислите среднее значение функции стоимости на последних 10 000 примеров тренировочного набора, к какому из значений ваш ответ ближе всего?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 17.54\n",
    "2. 18.64\n",
    "3. **19.74**\n",
    "4. 20.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Тестирование модели\n",
    "\n",
    "В базовой модели первые 100 000 строк используются для обучения, а оставшиеся – для тестирования. Как вы можете заметить, значение отрицательного логарифмического правдоподобия не очень информативно, хоть и позволяет сравнивать разные модели. В качестве четвертого задания вам необходимо модифицировать базовую модель таким образом, чтобы метод `iterate_file` возвращал значение _точности_ на тестовой части набора данных. \n",
    "\n",
    "Точность определим следующим образом:\n",
    "- считаем, что тег у вопроса присутствует, если спрогнозированная вероятность тега больше 0.9\n",
    "- точность одного примера расчитывается как [коэффициент Жаккара](https://ru.wikipedia.org/wiki/Коэффициент_Жаккара) между множеством настоящих тегов и предсказанных моделью\n",
    "  - например, если у примера настоящие теги ['html', 'jquery'], а по версии модели ['ios', 'html', 'java'], то коэффициент Жаккара будет равен |['html', 'jquery'] $\\cap$ ['ios', 'html', 'java']| / |['html', 'jquery'] $\\cup$ ['ios', 'html', 'java']| = |['html']| / |['jquery', 'ios', 'html', 'java']| = 1/4\n",
    "- метод `iterate_file` возвращает **среднюю** точность на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь\n",
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы создаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "        \n",
    "    accuracy_level : float, default=0.9\n",
    "        порог спрогнозированной вероятности тега\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     accuracy_level=0.9):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        self._accuracy = []\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "                \n",
    "                predicted_tags = []\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        # z += ...\n",
    "                        # прибавляем вес для слова word тега tag\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sigma = ...\n",
    "                    if z >= 0:\n",
    "                        sigma = 1 / (1 + np.exp(-z))\n",
    "                    else:\n",
    "                        sigma = 1 - 1/(1 + np.exp(z))\n",
    "    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sample_loss += ...\n",
    "                    if y ==1:\n",
    "                        sample_loss += (-y * np.log(np.max([tolerance, sigma]))) \n",
    "                    else:\n",
    "                        sample_loss += (-(1 - y) * np.log(1 - np.min([1 - tolerance, sigma])))\n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        # dLdw = ...\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate * dLdw\n",
    "                        self._b[tag] -= -learning_rate * dLdw\n",
    "                    else:\n",
    "                        if sigma > accuracy_level:\n",
    "                            predicted_tags.append(tag)\n",
    "                        \n",
    "                self._loss.append(sample_loss)\n",
    "                \n",
    "                if n >= top_n_train:\n",
    "                    self._accuracy.append(len(tags.intersection(predicted_tags)) / len(tags.union(predicted_tags)))\n",
    "                    \n",
    "                n += 1\n",
    "                    \n",
    "        return np.mean(self._accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d21f124bb74b3abce0eb048830b160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.59\n"
     ]
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "# выведем полученное значение с точностью до двух знаков\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 4.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.39\n",
    "2. 0.49\n",
    "3. **0.59**\n",
    "4. 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. $L_2$-регуляризация\n",
    "\n",
    "В качестве пятого задания вам необходимо добавить в класс `LogRegressor` поддержку $L_2$-регуляризации. В методе `iterate_file` должен появиться параметр `lmbda=0.01` со значением по умолчанию. С учетом регуляризации новая функция стоимости примет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\frac{\\lambda}{2} \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2\n",
    "\\end{array}$$\n",
    "\n",
    "Градиент первого члена суммы мы уже вывели, а для второго он имеет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\frac{\\lambda}{2} R\\left(W\\right) &=& \\lambda w_{ki}\n",
    "\\end{array}$$\n",
    "\n",
    "Если мы на каждом примере будем делать честное обновление всех весов, то все очень замедлится, ведь нам придется на каждой итерации пробегать по всем словам словаря. В ущерб теоретической корректности мы используем грязный трюк: будем регуляризировать только те слова, которые присутствуют в текущем предложении. Не забывайте, что смещение (bias) не регуляризируется. `sample_loss` тоже должен остаться без изменений.\n",
    "\n",
    "Замечание:\n",
    "- не забудьте, что нужно учитывать регуляризацию слова в градиентном шаге только один раз\n",
    "- условимся, что учитываем регуляризацию только при первой встрече слова\n",
    "- если бы мы считали сначала bag-of-words, то мы бы в цикле шли по уникальным словам, но т.к. мы этого не делаем, приходится выкручиваться (еще одна жертва богу online-моделей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь\n",
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы создаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "        \n",
    "    accuracy_level : float, default=0.9\n",
    "        порог спрогнозированной вероятности тега\n",
    "        \n",
    "    lmbda : float, default=0.01\n",
    "        параметр l_2-регуляризации\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     accuracy_level=0.9,\n",
    "                     lmbda=0.01):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        self._accuracy = []\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "                \n",
    "                predicted_tags = []\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        # z += ...\n",
    "                        # прибавляем вес для слова word тега tag\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sigma = ...\n",
    "                    if z >= 0:\n",
    "                        sigma = 1 / (1 + np.exp(-z))\n",
    "                    else:\n",
    "                        sigma = 1 - 1/(1 + np.exp(z))\n",
    "    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sample_loss += ...\n",
    "                    if y ==1:\n",
    "                        sample_loss += (-y * np.log(np.max([tolerance, sigma]))) \n",
    "                    else:\n",
    "                        sample_loss += (-(1 - y) * np.log(1 - np.min([1 - tolerance, sigma])))\n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        # dLdw = ...\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate * dLdw \\\n",
    "                                                + learning_rate * lmbda * self._w[tag][self._vocab[word]]\n",
    "                        self._b[tag] -= -learning_rate * dLdw\n",
    "                    else:\n",
    "                        if sigma > accuracy_level:\n",
    "                            predicted_tags.append(tag)\n",
    "                        \n",
    "                self._loss.append(sample_loss)\n",
    "                \n",
    "                if n >= top_n_train:\n",
    "                    self._accuracy.append(len(tags.intersection(predicted_tags)) / len(tags.union(predicted_tags)))\n",
    "                    \n",
    "                n += 1\n",
    "                    \n",
    "        return np.mean(self._accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4b68f1fc4e4527925838b85995ea19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.52\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f052d700da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 5.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.3\n",
    "2. 0.35\n",
    "3. 0.4\n",
    "4. **0.52**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ElasticNet регуляризация, вывод\n",
    "Помимо $L_2$ регуляризации, часто используется $L_1$ регуляризация.\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right|\n",
    "\\end{array}$$\n",
    "\n",
    "Если линейно объединить $L_1$ и $L_2$ регуляризацию, то полученный тип регуляризации называется ElasticNet:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\lambda R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$\n",
    "- где $\\gamma \\in \\left[0, 1\\right]$\n",
    "\n",
    "В качестве шестого вопроса вам предлагается вывести формулу градиента ElasticNet регуляризации (не учитывая $-\\mathcal{L}$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\frac{\\partial}{\\partial w_{ki}} \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) w_{ki}\\right)$ \n",
    "2. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma \\left|w_{ki}\\right| + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "3. $\\huge \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "4. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(\\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Регуляризация ElasticNet , реализация\n",
    "\n",
    "В качестве седьмой задачи вам предлается изменить класс `LogRegressor` таким образом, чтобы метод `iterate_file` принимал два параметра со значениями по умолчанию `lmbda=0.0002` и `gamma=0.1`. Сделайте один проход по датасету с включенной `ElasticNet`-регуляризацией и заданными значениями по умолчанию и ответьте на вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь\n",
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы создаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "        \n",
    "    accuracy_level : float, default=0.9\n",
    "        порог спрогнозированной вероятности тега\n",
    "        \n",
    "    lmbda : float, default=0.0002\n",
    "        параметр l_2-регуляризации\n",
    "    \n",
    "    gamma : float, default=0.1\n",
    "        параметр l_1-регуляризации\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     accuracy_level=0.9,\n",
    "                     lmbda=0.0002,\n",
    "                     gamma=0.1):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        self._accuracy = []\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "                \n",
    "                predicted_tags = []\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        # z += ...\n",
    "                        # прибавляем вес для слова word тега tag\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sigma = ...\n",
    "                    if z >= 0:\n",
    "                        sigma = 1 / (1 + np.exp(-z))\n",
    "                    else:\n",
    "                        sigma = 1 - 1/(1 + np.exp(z))\n",
    "    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sample_loss += ...\n",
    "                    if y ==1:\n",
    "                        sample_loss += (-y * np.log(np.max([tolerance, sigma]))) \n",
    "                    else:\n",
    "                        sample_loss += (-(1 - y) * np.log(1 - np.min([1 - tolerance, sigma])))\n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        # dLdw = ...\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate * dLdw \\\n",
    "                                    + 2 * learning_rate * lmbda * gamma * self._w[tag][self._vocab[word]] \\\n",
    "                                    + learning_rate * lmbda * (1 - gamma) * np.sign(self._w[tag][self._vocab[word]])\n",
    "                        self._b[tag] -= -learning_rate * dLdw\n",
    "                    else:\n",
    "                        if sigma > accuracy_level:\n",
    "                            predicted_tags.append(tag)\n",
    "                        \n",
    "                self._loss.append(sample_loss)\n",
    "                \n",
    "                if n >= top_n_train:\n",
    "                    self._accuracy.append(len(tags.intersection(predicted_tags)) / len(tags.union(predicted_tags)))\n",
    "                    \n",
    "                n += 1\n",
    "                    \n",
    "        return np.mean(self._accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956e0a17dbe446fdbb3231e3bc25a70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.59\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f05380de0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 7.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. **0.59**\n",
    "2. 0.69\n",
    "3. 0.79\n",
    "4. 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Самые важные слова для тега\n",
    "\n",
    "Прелесть линейных моделей в том, что они легко интерпретируемы. Вам предлагается вычислить, какие слова вносят наибольший вклад в вероятность появления каждого из тегов. А затем ответьте на контрольный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "javascript : javascript, x20, 125, x30, x44\n",
      "android : android, activity, arm, imgsrv, 29297\n",
      "java : hibernate, servlet, println, spring, java\n",
      "jquery : jquery, ready, ajax, val, sdf\n",
      "ios : ios, nsstring, nil, xcode, iphone\n",
      "python : python, def, py, django, np\n",
      "php : php, x5c, echo, 125, _post\n",
      "c++ : avrf, c++, std, cout, trace\n",
      "c# : xsl, writeline, binding, net, linq\n",
      "html : html, br, nbsp, amp, span\n"
     ]
    }
   ],
   "source": [
    "model._vocab_inv = dict([(v, k) for (k, v) in model._vocab.items()])\n",
    "\n",
    "for tag in model._tags:\n",
    "    print(tag, ':', ', '.join([model._vocab_inv[k] for (k, v) in \n",
    "                               sorted(model._w[tag].items(), \n",
    "                                      key=lambda t: t[1], \n",
    "                                      reverse=True)[:5]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 8.</font> Для многих тегов наличие самого тега в предложении является важным сигналом, у многих сам тег является самым сильным сигналом, что не удивительно. Для каких из тегов само название тега не входит в топ-5 самых важных?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. **c#** \n",
    "2. javascript\n",
    "3. jquery\n",
    "4. android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Сокращаем размер словаря\n",
    "Сейчас количество слов в словаре – 519290, если бы это была выборка из 10 миллионов вопросов с сайта StackOverflow, то размер словаря был бы миллионов 10. Регуляризировать модель можно не только изящно математически, но и топорно, например, ограничить размер словаря. Вам предоставляется возможность внести следующие изменения в класс `LogRegressor`:\n",
    "- добавить в метод `iterate_file` еще один аргумент со значением по умолчанию `update_vocab=True`\n",
    "- при `update_vocab=True` разрешать добавлять слова в словарь в режиме обучения\n",
    "- при `update_vocab=False` игнорировать слова не из словаря\n",
    "- добавить в класс метод `filter_vocab(n=10000)`, который оставит в словаре только топ-n самых популярных слов, используя данные из ``train``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь\n",
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы создаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "        \n",
    "        self._stats = defaultdict(int)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "        \n",
    "    accuracy_level : float, default=0.9\n",
    "        порог спрогнозированной вероятности тега\n",
    "        \n",
    "    lmbda : float, default=0.0002\n",
    "        параметр l_2-регуляризации\n",
    "    \n",
    "    gamma : float, default=0.1\n",
    "        параметр l_1-регуляризации\n",
    "        \n",
    "    update_vocab: boolean, default=True\n",
    "        разрешать добавлять слова в словарь в режиме обучения\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     accuracy_level=0.9,\n",
    "                     lmbda=0.0002,\n",
    "                     gamma=0.1,\n",
    "                     update_vocab=True):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        self._accuracy = []\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "                \n",
    "                predicted_tags = []\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab and update_vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        if word not in self._vocab:\n",
    "                            continue\n",
    "                        if update_vocab:\n",
    "                            self._stats[self._vocab[word]] += 1\n",
    "                        # z += ...\n",
    "                        # прибавляем вес для слова word тега tag\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sigma = ...\n",
    "                    if z >= 0:\n",
    "                        sigma = 1 / (1 + np.exp(-z))\n",
    "                    else:\n",
    "                        sigma = 1 - 1/(1 + np.exp(z))\n",
    "    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sample_loss += ...\n",
    "                    if y ==1:\n",
    "                        sample_loss += (-y * np.log(np.max([tolerance, sigma]))) \n",
    "                    else:\n",
    "                        sample_loss += (-(1 - y) * np.log(1 - np.min([1 - tolerance, sigma])))\n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        # dLdw = ...\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:\n",
    "                            if word not in self._vocab:\n",
    "                                continue\n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate * dLdw \\\n",
    "                                    + 2 * learning_rate * lmbda * gamma * self._w[tag][self._vocab[word]] \\\n",
    "                                    + learning_rate * lmbda * (1 - gamma) * np.sign(self._w[tag][self._vocab[word]])\n",
    "                        self._b[tag] -= -learning_rate * dLdw\n",
    "                    else:\n",
    "                        if sigma > accuracy_level:\n",
    "                            predicted_tags.append(tag)\n",
    "                        \n",
    "                self._loss.append(sample_loss)\n",
    "                \n",
    "                if n >= top_n_train:\n",
    "                    self._accuracy.append(len(tags.intersection(predicted_tags)) / len(tags.union(predicted_tags)))\n",
    "                    \n",
    "                n += 1\n",
    "                    \n",
    "        return np.mean(self._accuracy)\n",
    "    \n",
    "    \"\"\"\n",
    "    оставляет в словаре только топ-n самых популярных слов, используя данные из train\n",
    "    \"\"\"\n",
    "    def filter_vocab(self, n=10000):\n",
    "\n",
    "        filtered_words = set([k for (k, v) in sorted(self._stats.items(), \n",
    "                                                      key=lambda t: t[1], reverse=True)[:n]])\n",
    "        self._vocab = dict([(k, v) for (k, v) in self._vocab.items() if v in filtered_words])\n",
    "        for tag in self._tags:\n",
    "            self._w[tag] = dict([(k, v) for (k, v) in self._w[tag].items() if k in filtered_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4684eeecc141cfb2048a7dfe954c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.59\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbceb09eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оставим только топ 10 000 слов\n",
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51dd55c8481b42d1b8fb5c5829b69b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.69\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD1CAYAAACm0cXeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl8VNX9//HXJIGw74ishs1TZBfCIiaiqEWLilXRoriLO1VptS6/+m1tf36tgtW6VREprrhrcQO3BpAlyiJQPIKIEtYQCCFA9vn+MZNhJjNZyczcybyfjwcP7j333plPJjefnJx7Fpfb7UZERGJTQrQDEBGRulMSFxGJYUriIiIxTElcRCSGKYmLiMQwJXERkRiWFM4Xz84+oP6LIiK11LFjS1dNz1VNXEQkhimJi4jEMCVxEZEYpiQuIhLDlMRFRGKYkriISAxTEhcRiWFK4iIiMcyRSbyguJTUGRk88vmmaIciIuJojkziCS7PYKV5q7ZHORIREWdzZBJvnOQJq1WTsM4KICIS8xyZxMuV18hFRCQ0Ryfx3MPF0Q5BRMTRHJ3ERUSkao5P4mVuzWYrIlIZxybxq0Z2ByC/sCTKkYiIOJdjk3jnVk0AyC8sjXIkIiLO5dgk3trbvfBgkWriIiKVcWwS33OwCIC1Ow5EORIREedybBLvf2xL4EiNXEREgjk2ibdt1hiAg0VqExcRqYxjk3j5kPv31+6MciQiIs7l2CTevHEiAGu250U5EhER53JsEndp3hQRkWo5Non7Ky3TqE0RkVAcncT7dmwOwEOfbYxyJCIizuToJL4x+yAA73yrh5siIqE4Ook/ccFA33aJmlRERII4OomPTGnr275kztdRjERExJmqHQ5pjJkNTAB2W2sHeMv+B7gOyPaedo+19sNwBQnw077D4Xx5EZGYVJOa+BxgfIjyR621Q7z/wpbA37kmNVwvLSIS86pN4tbaDGBvBGIJqVubpr7tp5dsiVYYIiKOdDRt4rcYY741xsw2xrSt/vSjN3vZz5F4GxGRmFHXJP400BsYAuwAZtRbRCEkJx0JM3VGRjjfSkQkptQpiVtrd1lrS621ZcBzwIj6DSvQomljwvnyIiIxq05J3BjT2W/3fGBd/YQTmsvlYvkdab599RkXEfGoSRfDV4GxQAdjTBZwPzDWGDMEcANbgOvDGCMACX4TYn28YRd/+vh7pp50HNeNPi7cby0i4lgutzt8tdrs7AP1+uJ/+tgyf/2ugLLM6en1+RYiIlHXsWPLGk/j6ugRmxVNP7V3tEMQEXGUmEriLZK13qaIiL+YSuKh/GXB99EOQUQkamI+ib+nNThFJI7FXBJ/7YphQWU78wqY/u561mzbT2FJWRSiEhGJjpjqneLPf+RmqyZJ5BWU+PZnXTKYwV1bh+utRUTCqja9U2I2ia/bkcdVr6yu9Hi7Zo3Ye6gYQP3JRSSmNNguhv4GdG7FV7edXOnx8gQO8OxXP5GdXxiJsEREIipmkzhAo8Sah3/2P5eHMRIRkeiI6STu7w+n92FUSkRmxBURcYyYbRMvV1xaRoLLRWKCpwmp4lS1j5zXn9+9tx7QEH0RiQ21aROP+SGQFZtUPrx+JO+t3cmE/p04tlWTgGM78wqCykREYlmDaU4p17FFMteOPi5ksn7sP5ujEJGISPg0uCQeymO/HgDA0G5tohyJiEj9iosk3qt9MwAe/nwT4XwGICISaXGRxDu2SPZt/7j3kG8752ARG7PzoxGSiEi9iIskXt5zBWD1tjzf9vhnljF57spohCQiUi/iIokD/O3cEwB4cOFGAA4Xl/qOvb1me1RiEhE5WnGTxE/p0z5gP/3xJb7tBz/dxLIteyMdkojIUYubJJ7gcnFWv2No3jgx5PFb31pH6owMSsr04FNEYkfcJHGAjzbs5mBRKXOW/1zpOb9+fkUEIxIROTpxlcTLPbl4i2/7g6kjA47tyCtUbVxEYkZcJfF/XzciqOyYlsmsuCONSUO6+MpmfvFDJMMSEamzuEriFYfiL7xxNAAul4vfj+vjK39j9XaWbNaDThFxvrhK4gB/PtsAMHNif9o0axRw7B8XDPBt3/bOuojGJSJSFzE/i2FtndWvEyN6tKV988ZBx0altAvYLyktIyHBRXZ+EZ1aJgedLyISbXGXxIGQCTyU99fv8g0OAs1HLiLOE3fNKdX54paTSE7yfCz+CRwgr6A41CUiIlGjJF5Bi+QkbjulV8hj763dGeFoRESqVm0SN8bMNsbsNsYEPekzxkw3xriNMR3CE150XOjX3dDf4xk/RjgSEZGq1aQmPgcYX7HQGNMdOBOofPijiIiEVbUPNq21GcaYlBCHHgXuBN6r76CcYOntafy09xBZuQUkJbq47W11ORQR56lTm7gx5jxgm7V2TT3H4xhJCS56d2jOKX3aM6bnka6HqTMy2JlXEMXIRESOqHUSN8Y0A+4B/lj/4cSG11dtp6ikjDIt9SYiUVaXmnhvoCewxhizBegGrDTGHFuPcTnONaN6+LZf/DqLMY8t5sbXvwWgtMzN2H8sIXVGBm+s1gITIhI5tU7i1tq11tpjrLUp1toUIAs40VrboPvf3TAmhWcmDQooW5m1H4CLXsjkYJFnpaC/fbbJd3xzzkGKSsoiF6SIxJ2adDF8FVjq2TRZxphrwh+WMw3r3iaoLPdQMVtzg9vIN2bnc/Gcb7hoztcB5Vv2HuJAQQl5BcXYXVqkWUSOjssdxnbd7OwDDa7ReEvOoaDEXNF9Z/blLwuOjPZccUcaLpeL/YeLOf2ppQHnLpo2hiaNQq82JCLxqWPHlq7qz/JQEq+D1BkZtTp/bJ/2LN2yj8IQTSvXjurB9WNS6ikyEWkIapPENey+DjKnpzNn8pCAssuGd6v0/C835YRM4ACzlmmslIjUnWriR6mopIy1O/IY1r0N+YUlnPrEV7V+Dc2OKCL+VBOPoMZJCb4Hni2Sk2qUkJ+6aKBvcQoRkaOhJB4Gx7VtCngeWi68aXTQ8dQebTmrXyff/sGikojFJiINi5pTwqCktIySMndArxO3282Dn27kpjE9fcvClT8gvXBwZ+46vW9UYhUR51FzSpQlJSYEdRt0uVzcc8bxAet6pvXyzMny5podlJa5OZpfqF//nMvcFVvrfL2IxCbVxKPox5xDTPLrc96lVTLvXTcy5LnfbM0lpV2zoKXl9hws4qxnlvn29ZBUJPbVpiYel2tsOkXP9s0C9rfnFTJv5TYuPrGrr+zdb3fw7fY8/r1+FwDPTBrEsO5t2HWgkE4tkwMSOEBBcakGD4nEESVxh3nkix98SfyZJVt4vkI/8hu8k25VJiu3gD4dm4ctPhFxFiVxB6rtiFB/L3+Txf3j1X1RJF7owWaUzbl0KGP7tA/ZFbE2zjQdAZjvbXYRkfigJB5l/Y9tycPn9adN00ZMHtY15DkvXXYimdPTefvqVC5PDR7enzk9netOOs63X16TL3O7WbJ5b3gCFxFHUHOKg9w+tjd78otYYLN9Ze9em0rX1p7BQ93bNuXW9F70aNuUds0ak9a7ve+8lHaBD0mzcg9z/vOZAFw5ojs3p/WMwFcgIpGmLoYOU1BcStrjSwBYdnsaiQk17mlUZVu6uh6KxA4N9olhTRolMi29Jw9O6FerBA4w65LBYYpKRJxKSdyBpqR253Tvg8raGNy1NS9eNrTS43vyCykt0x9HIg2JmlMaoPfX7WRj9kEmDjyWS/71TdBxNa2IOJtGbMa5cwccW+XxBd/t5gzTEZfryH3y+ffZ3PXvDTRJSmDRb08Od4giUk/UnNLAXTuqR1DZvR98x4RnlweU3fXvDQAUlJSxKmt/RGKrzo85h1i8OSeo3O7KZ8F3uykpDb1akkg8URJv4K4fk8JHN4wKKt+dX1TpNVPnraGkzM098zdwoCAyc52vytrP+h15AWWT5nzN7e+sZ/76nQHll720kns/+I7Rf18ckdhEnExJPA50qDDzYblxT35FQXEpH20IHuV5+zvrWGizOe3J2i83VxdT563hyldW43a7KaqwHumfPv7et12xG+X189ZQUFwakRhFnEgPNuPE3kNFNE5M4FObzV8XbqzVtS9eNpQf9hwivXd7Wjap/8coU+etCWrCmXXJYK59bU2NX0MPa6Uhqc2DTSXxOFT+ELOid69NZeKszCqvre9kufdQEb98eln1J1bj9SuHB03tKxKrNNhHqnTa8aH7oHdt3ZTPbz4pYnGsztpf5wQ+cWBgD5wHP92I2+1m+rvruX7eGsrCWDkRcRIl8Th19xmBa3r29c5BXl1zSWFJ/fUIuW5eYHPJF7dU/Qvk8tTuPHzuCXx560ncc0ZfMqenc1a/YwDPg9HNOYfI+CGHlVn7ya7iwa1IQ6IkHqd+PagzD53Tz7e/Mftg0DmDurQKKnsxs37W8Qz1y6BFclJQc0167/a8PMUzi+Ot6T0Z27cDzRsn+fq433fm8b5z/Qc25R4urpc4RZxOg33iWIvkI9/+lHZNfdv+iXTNtv0BDxj/+dVPXDvaM+3ti5lbGZ3Srk4rCV332uqQ7wfQvnljcg56atJ3n9G30t41AI2TQtdDLntxpR52SlxQTTyOpfZo49v+4y9DrwY0uGtrMqen89VtgaM47/tgA49n/Mhv5gYP669OmdvNhl35lR6fln5k2tyqEni5FXekhSxPnZFRr80/Ik6k3ilxrrTMzY68Arq1aVrtueV9tB+c0I+75wf2bllxR1rAMP7KXP7SyoAE7j9fur/NOQfp2a5ZjV4TYGN2PpPnrgx5rKaxiThFvfZOMcbMNsbsNsas8yt7wBjzrTFmtTFmgTGmS12DlehKTHDVKIH7q5jAARb6LWRR0c68AnIPF1NcWhZUAw+VwAF6tW9eq8Tbt2ML7jmjL+9dOyLo2IiZiwhnZUUkmmrSnDIHGF+h7GFr7SBr7RBgPvDH+g5MnOeJCwdWeuzeD74LKnO73Ty/7CfOeW4FZzy1lLOeCexO+OoVw+o1vvMHdaZL6yYhm1cWfFf5LxmRWFZtErfWZgB7K5T5T3LRHFA1Jw6MPK5twP7jFwzg4XNPCDqvqKSM/MISRsxcxDNLfvKV768wD0ufDrV/IFoTLpeLd65JDSi778Pv2JlXEJb3E4mmOj/YNMb81RizFbgU1cTjRvnqQZ/dPJrRKe0YWKEbYmFJGWMeW8ypT0RmzpXKdGvTNOABKcA5z62IUjQi4VPnJG6tvdda2x14Gbil/kISJyvvrdKqSSPA0x2w3OLNOZz8WM1mFhzvHaQTTlNSu7O8kp4rIg1FfXQxfBm4oB5eR2Lc7e+sr9F5i6aN4YGzfxHmaDwSXK6A/uJvrt5O6owMvtt1ICLvLxJudUrixhj/MdvnAcFPtSRuVLWuZ+b0dDKnp/PZzaNJadeUz24eTZNGiRGMLtBDn20CYMpLqyjWohLSAFQ7YtMY8yowFuhgjMkC7gfONsYYoAz4CbghnEGKs5ljWgSVvTB5CHl+DzJbNWnEG1elBp0XTSt+zmVMz3bRDkPkqGiwj9QL/8UarhnVgxvGpEQvmBA+37iHu97/b1C5huaLE2kqWom4L2/1zED4xlXDHZfAAU7oFPzXAsAGtY1LjFMSl3rRvLFnBsKUds5cmOGYlsm+7QsGd/ZtX/7SqmiEI1JvlMQlLiS4XDx90SDOMB25a1wfTu6ltnBpGDQVrcSN4T3aMNw7c+MZpiOLN3sGIpe53SRogiyJUaqJS1zy71Ez6YWvoxiJyNFREpe41LtDc840nrVGf9p3OMrRiNSduhhK3CotczPq0UUBZV/cclLAikci0aAuhiI1kJgQ/HMS7Ym7RGpLSVzi2ktTTgwqy8pV84rEDiVxiWuhpgwoKNacKhI7lMQl7i28cTSdWiYzeVhXAP74keZzk9ihJC5xr02zRsyfOpKcg0UAbMw+SJnW5JQYoSQu4jVpaFff9rodmlNFYoOSuIiXf/v4nSFmPBRxIiVxEa/kpAT+/4R+AOQcLAqYXlfEqZTERfycfnyHaIcgUitK4iJ+XBUmwkqdkaF+4+JoSuIiFVRc7ef85zMJ5/QUIkdDSVwkhKtHdg/YfzEzK0qRiFRNSVwkhBtP7hmw73J5huOXlGo0pziLZjEUqcL89Tv508ffB5RpcWUJN81iKFJPhnVvE1S2bkdeFCIRCU1JXKQKnVs1CSq76pXVUYhEJDQlcRGRGKYkLlKNl71zjr99daqvbNt+9R0XZ9CDTZFaqDgUf9Ylg/nt2+v49OaTSAqxUpBIXdTmwaaSuEgtfLs9j2teDd0mvuKONMrcUFxaRpNGiRGOTBqS2iRxrQgrUguDurSq9Ngd765n8ea9vn11RZRIUJu4SC2d2K11yHL/BC4SKdXWxI0xs4EJwG5r7QBv2cPAOUAR8ANwlbU2N5yBijjFjzmHAvbbNWvE3kPFQecVFJeqWUXCriY18TnA+AplC4EB1tpBwPfA3fUcl4hjLbhpNBcP7cKCG0eROT2dT24cHfK8T7/PjnBkEo9q9GDTGJMCzC+viVc4dj5wobX20orH9GBT4sWholKKSsto1SSJeau2M/OLHwC1i0vdRHrY/dXAR/XwOiIxq1njRNo0bUSCy8XFQ7v4ylNnZFBSprqMhM9RJXFjzL1ACfBy/YQjEvsSKiws8dzSn6IUicSDOidxY8yVeB54XmqtVVVDpBKzl/1MXkHwg0+R+lCnJG6MGQ/cCZxrrT1U3fki8WbZ7WnMnNjftz/uyaWs2bY/ihFJQ1WTLoavAmOBDsaYLOB+PL1RkoGFxhiAZdbaG8IYp0hMSUxwkda7fUDZjrxCBneNUkDSYGnYvUgYVZxrZcUdaUDwgswi/jTsXsShRsxc5Nv+58WDWPFTLlNSu9G8sX4UpW5UExcJo4o18cqoP7n40/JsIg7x/G+GkNarHW9cObzK877cuEeLMEudqCYuEiHvfruDvy7cWOnxRokuvrotLYIRiVOpTVzEgSYO6szEQZ3JKyhm3JNLg44Xl6rOI7WnmrhIFO3MK+Cc51YElN05rg8XDelSyRUSD7Syj0gMyS8s4dQnvgoo+39nHs8DC77ntlN68ff/bAZg6knHcd3o46IRokSYkrhIjMnKPcz5z2fW6FwXMPeyoUx5aRUvTB7CgM6VrzYksUm9U0RiTLc2TWt8rhuY8tIqAK56JfR6nxI/lMRFHGLBjaOYlt6z1tdtzjlYq/Onv7ue1BkZpM7IIL+wpNbvJ86iJC7iEG2bNWZKanf6dWoBwAWDO/uOZU5P5+2rU0Ned/Gcb2r1Phk/5Pi2K7bFS+xRF0MRh5n9myGszNrPiOPacvvY3iQleJpHu7dtyic3juKXTy8DYPKwrrzyzTYAikvLaJRYeZ2sfOToC5OHhDl6iTQ92BSJMXvyC2nVpBGNkxJ8yfkXx7TgxSknVnpNVcP/f3dqby4+UdMrOokebIo0YB1aJNM4yfOj2zLZ88f0d7vzCVUh+zHnEAtt8ILNL/sl/Ee864FKbFISF4lhT1000Lc9YuYipr21NuD4pDlfc8/8DUHXlf8SKLcqSwtWxColcZEY9otOLQP2l27ZR1kNmkh7tG3KRzeM8u1PnbeGXQcK+WHPQV7M3MruA4XsP1zMpBe+pqhEE3M5mdrERWJcQXEpaY8vCSr/9KbRnP7UkTla/nnxID61e7jp5BRaeJth1u3Iq1Ff8xV3pGkhiwjSBFgicaRJo8SQ5f4JvHy+8hO7tQk4p6ajPTftOUjfji3qGKGEk5pTRBqAzOnpzLpkcNhef/LclRwoqNvAoMKSMkrK9Ed5uCiJizQQg7u2ZtYlg+nYonFA+UfXj6zyuszp6Sy9PY3GiS4mDjw24Njlqd1926c9WfuBQTvzCjj5scWMfnSR2tbDRElcpAEZ3LU1H14/ikXTxvjKOrRIrva6pAQXS25L494zj+fGMSkAfHj9SG6tMA3AfzblhLg60J8/tjz6pafbov80u3/4939r8iVILenBpkgD9fGG3RSWlHLewM7Vn+ynzO0mr6CENk0bAfDfnQe44uVVvuOVrQdak4ekn908mlZNGtUqnnikqWhFpF75j/gc2rUVq7blcdXI7tx0cs+Q51RFi0JXTyM2RaRePX3RIN/2qm15ALywfKuvTA8uo0dJXESqNbxHm5DlJaWeh5VLNu/1lS27PY3Lhnfz7f/5bENiwpGK5ZOLfmTdjjwKikvDFG18URIXkRrxH+FZ7pus/RQUl/K799YDkNarHYkJLn57Si9evWIYI3q0YfwvjmHZ7Wm+a+as2MpVr6z2rWRUUFzKfzblMO2ttbz8dRYFxaUh54GR0NQmLiI1tjE7n5/3HebLTTl8vGF30PFPbhxFu2aNQ1wJ987fwIIKk3FlTk8P2Zber1ML5l5W+ayMDZ3axEUkLPp2bMG44zty35nHhzxeWQIH+OuEfr4eL9XZsCufbfsPUxiib3lBcSmpMzK4tcJkX/FKSVxEai05KTh11KTXySc3jmJ499a+/araxSfOyuTkxxYHv8/PuQAs27KvJqE2eEriIlIn/qM5ayrB5eLpSYOZOvo4AOat2l7tNeWJPiv3MKkzMrjj3fW+Y6XqFVP9BFjGmNnABGC3tXaAt+wi4H+AfsAIa+3X4QxSRJznlrQU5mZurf7EEFZmeWrTTyz60VdWXpMvc7sZOXPRkfKfc0nr3d73INTf+GeWkXu4mMtTuweNLo0XNamJzwHGVyhbB/waqFnvfhFpcFwuF5nT03nonH6suCOt+gv8POXX7xzgznF9fNsJ3tcd0NkzV/oDn3zPhl0HQr5O7uFiAOZmbo3bHi3VJnFrbQawt0LZBmutDVtUIhIzTju+Y63nGne5XNx2Si/f/q8HBU8NMHNifwD2HS7m8pdWBR2vaMKzy2sVQ0Oh+cRFJCouHd6NlslJbNxzMGAwULnKerJMGtKFm9N6cso/AhfC2J1fRH5hiW/Bi3ihB5siEjXnDjyW6af2DnnM5XLRt2PzgLJF08bw+3F9aNY4kTeuHA7Au9em+o5f/Wr1qxQ1NEriIuJYT10Y2Hbuv4pRSvtmZE5Pp2vrplye6hnm/2POoYjG5wRK4iLiWG2aNeKhc08AYFoVvU9uSYvPnilQg2H3xphXgbFAB2AXcD+eB53/ADoCucBqa+0vK16rYfciUh9Ky9wh2839lQ/fbwhzlms+cRGJO/5zsMT6nOWaO0VE4s6fzjK+7bXb82p83dR5a5j+7nqWx+gwfiVxEWkQzj6hk2/bv5fKnvxCUmdkcO/8DUHXlJSWsSprPxk/5HBLjE6opSQuIg3GUxcNPLK92DOk/6x/egYBVZwGNyv3MKP/HjjBViyO+lQSF5EGY1j3IysQvbB8K59UmPM8dUYGbrcbt9sdci6Wfd5h/LFESVxEGowEl4sPpo707d/34XdB54yYuYjlPwW2f//N243x+aU/hzfAMFASF5EG5ZiWyUFlFSfouvWtdb7tR847wVcDf3119VPjOo2SuIg0eC6Xi9+f1ieo/JlJgzilTwd+5fdQtCjEakIAz361hdQZGRx22ALPSuIi0uC8dfWR+VTmXDoUgElDu3BrhZGd5W3o/isVjXlsMb9/bz0VPedtakl/fEnQsYo2ZudXuWpRfVISF5EGp0fbprwweQgzJ/an/7EtfeUXn9i1Rtd/uSmHRz7fVOnxshC9WErL3OQcLGJ11n4mz11JWg2SfX2IrzkbRSRuDOjcKqgsOSmhxqM5563azu9CNMEAzF+3iwcWfM/Vo3pw45gU8gqKGffk0qOKt65UExcRAZbedjIfTB1J51ZHHowWFJeydnseD38WWCvPLyoBYPYyTxNLtBI4aO4UEZEA+w4VcebTy0Ie+1X/TnywfldA2cVDu4Rc8HnRtDEBU+fWhibAEhE5ChfMzuTnfYdrfd29Z/RlfL9j6py8y2kCLBGRozDcb+Snv0fP71/ldRMHdT7qBF5bSuIiIhX8fpzngWa7Zo0Y1r01AH8+23Byr/acN/BYIHgAUfnqQpGm5hQRkaN0sKiE5o3rr7OfmlNERCKoPhN4bSmJi4jEMCVxEZEYpiQuIhLDlMRFRGKYkriISAxTEhcRiWFK4iIiMSysg31ERCS8VBMXEYlhSuIiIjFMSVxEJIbFzfJsxpjuwFygE+AGnrXWPmaMaQfMA1KALcAka+0+Y4wLeAw4GzgEXGmtXel9rSuA+7wv/Rdr7b+85cOAOUBT4EPgt9Zaxz50MMYkAl8D26y1E4wxPYHXgPbAN8AUa22RMSYZz2c3DMgBLrbWbvG+xt3ANUApMM1a+4m3fDyezy8RmGWt/d+IfnG1ZIxpA8wCBuC5P64GLHF4bxhjbgeuxfM5rAWuAjoTJ/eGMWY2MAHYba0d4C0Le56o7D2qizeeauIlwHRr7QnAKOBmY8wJwB+Az6y1fYHPvPsAZwF9vf+mAk+D75t5PzASGAHcb4xp673maeA6v+vGR+DrOhq/BTb47T8EPGqt7QPsw/MDiPf/fd7yR73n4f38LgH64/lanzLGJHp/OTyJ5zM8AfiN91wnewz42Fr7C2Awns8l7u4NY0xXYBow3JvAEvF8j+Pp3phD8PcnEvdCZe9RpbhJ4tbaHeW/Ia21B/D8kHYFzgP+5T3tX8BE7/Z5wFxrrdtauwxoY4zpDPwSWGit3ev9LbkQGO891spau8xbw5rr91qOY4zpBvwKT+0Tb43iNOBN7ykVP4vyz+hNYJz3/POA16y1hdbaH4FNeG7YEcAma+1ma20RnhrceeH/qurGGNMaSAeeB7DWFllrc4nTewPPX+hNjTFJQDNgB3F0b1hrM4C9FYojcS9U9h5Vipsk7s8YkwIMBZYDnay1O7yHduJpbgFPgt/qd1mWt6yq8qwQ5U71d+BOoMy73x7ItdaWePf94/d9zd7j+73n1/YzcqqeQDbwgjFmlTFmljGmOXF4b1hrtwGPAD/jSd778TSfxOu9US4S90Jl71GluEvixpgWwFvAbdbaPP9j3t+MjmynrE/GmPL2vm+iHYtDJAEnAk9ba4cCB6nwp2wc3Rtt8dQIewJdgOY4tOknWiJxL9TmPeIqiRtjGuFJ4C9ba9/2Fu/y/omD9//d3vKqNqk/AAAB6klEQVRtQHe/y7t5y6oq7xai3InGAOcaY7bg+XP2NDxtwm28f0JDYPy+r9l7vDWeh1i1/YycKgvIstYu9+6/iSepx+O9cTrwo7U221pbDLyN536J13ujXCTuhcreo0pxk8S97XTPAxustTP9Dr0PXOHdvgJ4z6/8cmOMyxgzCtjv/VPnE+BMY0xbb63lTOAT77E8Y8wo73td7vdajmKtvdta281am4Ln4dPn1tpLgS+AC72nVfwsyj+jC73nu73llxhjkr09W/oCK4BMoK8xpqcxprH3Pd6PwJdWJ9bancBWY4zxFo0D/ksc3ht4mlFGGWOaeWMt/yzi8t7wE4l7obL3qFLcdDHEU5uYAqw1xqz2lt0D/C/wujHmGuAnYJL32Id4ug1twtN16CoAa+1eY8wDeG5GgD9ba8sfgtzEka5DH3n/xZK7gNeMMX8BVuF90Of9/0VjzCY8D3wuAbDWrjfGvI7nh7wEuNlaWwpgjLkFz42cCMy21q6P6FdSe7cCL3sTy2Y83+8E4uzesNYuN8a8CazE8z1dBTwLfECc3BvGmFeBsUAHY0wWnl4mkcgTlb1HlTR3iohIDIub5hQRkYZISVxEJIYpiYuIxDAlcRGRGKYkLiISw5TERURimJK4iEgMUxIXEYlh/wf35S9Co1xw3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbd57f8a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# сделаем еще одну итерацию по датасету, уменьшив скорость обучения в 10 раз\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 9.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.48\n",
    "2. 0.58\n",
    "3. **0.68**\n",
    "4. 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Прогнозирование тегов для новых вопросов\n",
    "\n",
    "В завершение этого задания вам предлагается реализовать метод `predict_proba`, который принимает строку, содержащую вопрос, а возвращает список предсказанных тегов вопроса с их вероятностями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь\n",
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы создаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "        \n",
    "        self._stats = defaultdict(int)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "        \n",
    "    accuracy_level : float, default=0.9\n",
    "        порог спрогнозированной вероятности тега\n",
    "        \n",
    "    lmbda : float, default=0.0002\n",
    "        параметр l_2-регуляризации\n",
    "    \n",
    "    gamma : float, default=0.1\n",
    "        параметр l_1-регуляризации\n",
    "        \n",
    "    update_vocab: boolean, default=True\n",
    "        разрешать добавлять слова в словарь в режиме обучения\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     accuracy_level=0.9,\n",
    "                     lmbda=0.0002,\n",
    "                     gamma=0.1,\n",
    "                     update_vocab=True):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        self._accuracy = []\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "                \n",
    "                predicted_tags = []\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab and update_vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        if word not in self._vocab:\n",
    "                            continue\n",
    "                        if update_vocab:\n",
    "                            self._stats[self._vocab[word]] += 1\n",
    "                        # z += ...\n",
    "                        # прибавляем вес для слова word тега tag\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sigma = ...\n",
    "                    if z >= 0:\n",
    "                        sigma = 1 / (1 + np.exp(-z))\n",
    "                    else:\n",
    "                        sigma = 1 - 1/(1 + np.exp(z))\n",
    "    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sample_loss += ...\n",
    "                    if y ==1:\n",
    "                        sample_loss += (-y * np.log(np.max([tolerance, sigma]))) \n",
    "                    else:\n",
    "                        sample_loss += (-(1 - y) * np.log(1 - np.min([1 - tolerance, sigma])))\n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        # dLdw = ...\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:\n",
    "                            if word not in self._vocab:\n",
    "                                continue\n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate * dLdw \\\n",
    "                                    + 2 * learning_rate * lmbda * gamma * self._w[tag][self._vocab[word]] \\\n",
    "                                    + learning_rate * lmbda * (1 - gamma) * np.sign(self._w[tag][self._vocab[word]])\n",
    "                        self._b[tag] -= -learning_rate * dLdw\n",
    "                    else:\n",
    "                        if sigma > accuracy_level:\n",
    "                            predicted_tags.append(tag)\n",
    "                        \n",
    "                self._loss.append(sample_loss)\n",
    "                \n",
    "                if n >= top_n_train:\n",
    "                    self._accuracy.append(len(tags.intersection(predicted_tags)) / len(tags.union(predicted_tags)))\n",
    "                    \n",
    "                n += 1\n",
    "                    \n",
    "        return np.mean(self._accuracy)\n",
    "    \n",
    "    \"\"\"\n",
    "    оставляет в словаре только топ-n самых популярных слов, используя данные из train\n",
    "    \"\"\"\n",
    "    def filter_vocab(self, n=10000):\n",
    "\n",
    "        filtered_words = set([k for (k, v) in sorted(self._stats.items(), \n",
    "                                                      key=lambda t: t[1], reverse=True)[:n]])\n",
    "        self._vocab = dict([(k, v) for (k, v) in self._vocab.items() if v in filtered_words])\n",
    "        for tag in self._tags:\n",
    "            self._w[tag] = dict([(k, v) for (k, v) in self._w[tag].items() if k in filtered_words])\n",
    "            \n",
    "    \n",
    "    \"\"\"\n",
    "    принимает строку, содержащую вопрос, а возвращает список предсказанных тегов вопроса с их вероятностями.\n",
    "    \"\"\"\n",
    "    def predict_proba(self, string):\n",
    "        result = {}\n",
    "        for tag in self._tags:\n",
    "            z = self._b[tag]\n",
    "            for word in string.split(' '):\n",
    "                if word not in self._vocab:\n",
    "                    continue\n",
    "                    \n",
    "                z += self._w[tag][self._vocab[word]]\n",
    "                \n",
    "            if z >= 0:\n",
    "                sigma = 1 / (1 + np.exp(-z))\n",
    "            else:\n",
    "                sigma = 1 - 1/(1 + np.exp(z))\n",
    "                \n",
    "            result[tag] = sigma\n",
    "            \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b8865c64494f17a78832ecf112dc35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.59\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19dc533ca0e4a40be0b10518a42efe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.69\n"
     ]
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "model.filter_vocab(n=10000)\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = (\"I want to improve my coding skills, so I have planned write \" +\n",
    "            \"a Mobile Application.need to choose between Apple's iOS or Google's Android.\" +\n",
    "            \" my background: I have done basic programming in .Net,C/C++,Python and PHP \" +\n",
    "            \"in college, so got OOP concepts covered. about my skill level, I just know \" +\n",
    "            \"concepts and basic syntax. But can't write complex applications, if asked :(\" +\n",
    "            \" So decided to hone my skills, And I wanted to know which is easier to \" +\n",
    "            \"learn for a programming n00b. A) iOS which uses Objective C B) Android \" + \n",
    "            \"which uses Java. I want to decide based on difficulty \" + \n",
    "            \"level\").lower().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ios', 1.0),\n",
       " ('php', 0.9999999882758276),\n",
       " ('android', 1.2408386595996745e-07),\n",
       " ('c++', 0.0),\n",
       " ('html', 0.0),\n",
       " ('java', 0.0),\n",
       " ('c#', 0.0),\n",
       " ('javascript', 0.0),\n",
       " ('python', 0.0),\n",
       " ('jquery', 0.0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(model.predict_proba(sentence).items(), \n",
    "       key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 10.</font> Отметьте все теги, ассоциирующиеся с данным вопросом, если порог принятия равен $0.9$. То есть считаем, что вопросу надо поставить некоторый тег, если вероятность его появления, предсказанная моделью, больше или равна 0.9. \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. android\n",
    "2. **ios**\n",
    "3. **php**\n",
    "4. java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
